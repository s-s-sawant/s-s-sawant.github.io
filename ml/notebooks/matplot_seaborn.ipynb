{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "matplotlib-seaborn-intro",
   "metadata": {},
   "source": [
    "# Matplotlib & Seaborn for Data Science Interviews: 20 Essential Exercises\n",
    "\n",
    "## ðŸ“Š Master Data Visualization for ML/DS Roles\n",
    "\n",
    "Welcome to this comprehensive Matplotlib and Seaborn practice notebook designed specifically for data science and machine learning interviews! These exercises cover the most commonly asked visualization concepts in technical interviews, from basic plots to advanced statistical visualizations used in real-world ML projects.\n",
    "\n",
    "### ðŸ“š What You'll Master\n",
    "- Basic and advanced plotting with Matplotlib\n",
    "- Statistical visualizations with Seaborn\n",
    "- Exploratory Data Analysis (EDA) techniques\n",
    "- Custom plot styling and formatting\n",
    "- Interactive and publication-ready visualizations\n",
    "- Data storytelling through visualization\n",
    "\n",
    "### ðŸŽ¯ Interview Focus Areas\n",
    "- **Entry Level**: Basic plots, customization, simple EDA\n",
    "- **Mid Level**: Statistical plots, multi-panel figures, advanced customization\n",
    "- **Advanced**: Custom visualizations, performance optimization, complex layouts\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-1",
   "metadata": {},
   "source": [
    "### 1. Basic Plot Types and Customization (Entry Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hint-1",
   "metadata": {},
   "source": [
    "<details>\n<summary>ðŸ’¡ Click for hint</summary>\n\n**Interview Focus**: Fundamental plotting skills - essential for any data science role.\n\n**Key concepts**: plt.plot(), plt.scatter(), plt.bar(), plt.hist(), basic customization\n\n**Common Questions**: \"Create a simple visualization?\" \"Customize plot appearance?\"\n\n</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 100)\n",
    "y1 = np.sin(x) + np.random.normal(0, 0.1, 100)\n",
    "y2 = np.cos(x) + np.random.normal(0, 0.1, 100)\n",
    "categories = ['A', 'B', 'C', 'D', 'E']\n",
    "values = np.random.randint(10, 100, 5)\n",
    "data_points = np.random.randn(1000)\n",
    "\n",
    "# Basic plotting exercises\n",
    "\n",
    "# 1. Line plot with customization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# Your code here - create line plots for y1 and y2 with different styles\n",
    "# Add labels, title, legend, grid\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Scatter plot with color mapping\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# Your code here - create scatter plot with color based on values\n",
    "# Add colorbar, labels, title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Bar chart with error bars\n",
    "errors = np.random.uniform(5, 15, 5)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# Your code here - create bar chart with error bars\n",
    "# Customize colors, add value labels on bars\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Histogram with multiple datasets\n",
    "data1 = np.random.normal(0, 1, 1000)\n",
    "data2 = np.random.normal(2, 1.5, 1000)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# Your code here - create overlapping histograms\n",
    "# Use alpha for transparency, different colors\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Pie chart with customization\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# Your code here - create pie chart with exploded slice\n",
    "# Add percentages, custom colors\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Basic plots created successfully!\")\n",
    "print(f\"Sample data shapes: x={x.shape}, y1={y1.shape}, categories={len(categories)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Verify basic plotting setup\n",
    "print(f\"Matplotlib backend: {plt.get_backend()}\")\n",
    "print(f\"Sample data generated: {len(data_points) == 1000}\")\n",
    "print(f\"Categories defined: {len(categories) == 5}\")\n",
    "print(f\"X-axis range: {x.min():.1f} to {x.max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-2",
   "metadata": {},
   "source": [
    "### 2. Exploratory Data Analysis Visualizations (Entry-Mid Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hint-2",
   "metadata": {},
   "source": [
    "<details>\n<summary>ðŸ’¡ Click for hint</summary>\n\n**Interview Focus**: EDA techniques for understanding data distributions and relationships.\n\n**Key concepts**: Box plots, violin plots, pair plots, correlation heatmaps\n\n**Common Questions**: \"Visualize data distribution?\" \"Show relationships between variables?\"\n\n</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset for EDA\n",
    "np.random.seed(123)\n",
    "n_samples = 500\n",
    "\n",
    "# Generate correlated features\n",
    "feature1 = np.random.normal(50, 15, n_samples)\n",
    "feature2 = feature1 * 0.7 + np.random.normal(0, 10, n_samples)\n",
    "feature3 = np.random.exponential(2, n_samples)\n",
    "feature4 = np.random.uniform(0, 100, n_samples)\n",
    "target = 0.5 * feature1 + 0.3 * feature2 + np.random.normal(0, 5, n_samples)\n",
    "\n",
    "# Create DataFrame\n",
    "df_eda = pd.DataFrame({\n",
    "    'feature1': feature1,\n",
    "    'feature2': feature2,\n",
    "    'feature3': feature3,\n",
    "    'feature4': feature4,\n",
    "    'target': target,\n",
    "    'category': np.random.choice(['Type_A', 'Type_B', 'Type_C'], n_samples),\n",
    "    'group': np.random.choice(['Group_1', 'Group_2'], n_samples)\n",
    "})\n",
    "\n",
    "# EDA visualization exercises\n",
    "\n",
    "# 1. Distribution analysis with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "# Your code here - create histograms for each numeric feature\n",
    "# Add KDE curves, customize each subplot\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Box plots for comparing distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Your code here - box plots comparing features across categories\n",
    "# Use seaborn for better styling\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Correlation heatmap\n",
    "correlation_matrix = # Your code here - calculate correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# Your code here - create heatmap with annotations\n",
    "# Use diverging colormap, add correlation values\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Pair plot for feature relationships\n",
    "# Your code here - create pair plot using seaborn\n",
    "# Color by category, add regression lines\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 5. Violin plots for distribution comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# Your code here - violin plots comparing target across categories\n",
    "# Add inner quartiles, customize colors\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Outlier detection visualization\n",
    "def detect_outliers_iqr(data):\n",
    "    # Your code here - implement IQR method\n",
    "    pass\n",
    "\n",
    "outliers = detect_outliers_iqr(df_eda['feature1'])\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# Your code here - scatter plot highlighting outliers\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"EDA dataset shape: {df_eda.shape}\")\n",
    "print(f\"Correlation matrix shape: {correlation_matrix.shape}\")\n",
    "print(f\"Outliers detected: {len(outliers)}\")\n",
    "print(f\"Categories: {df_eda['category'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Verify EDA visualizations\n",
    "print(f\"Dataset created: {len(df_eda) == n_samples}\")\n",
    "print(f\"Correlation matrix computed: {correlation_matrix.shape == (5, 5)}\")\n",
    "print(f\"Features are correlated: {abs(correlation_matrix.loc['feature1', 'feature2']) > 0.5}\")\n",
    "print(f\"Categories present: {df_eda['category'].nunique() == 3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-3",
   "metadata": {},
   "source": [
    "### 3. Time Series Visualization (Mid Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hint-3",
   "metadata": {},
   "source": [
    "<details>\n<summary>ðŸ’¡ Click for hint</summary>\n\n**Interview Focus**: Time series analysis and temporal pattern visualization.\n\n**Key concepts**: Time series plots, seasonal decomposition, trend analysis, forecasting plots\n\n**Common Questions**: \"Visualize temporal trends?\" \"Show seasonal patterns?\"\n\n</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time series data\n",
    "np.random.seed(456)\n",
    "date_range = pd.date_range('2020-01-01', '2024-12-31', freq='D')\n",
    "n_days = len(date_range)\n",
    "\n",
    "# Create realistic time series with trend, seasonality, and noise\n",
    "trend = np.linspace(100, 200, n_days)\n",
    "seasonal_yearly = 20 * np.sin(2 * np.pi * np.arange(n_days) / 365.25)\n",
    "seasonal_weekly = 5 * np.sin(2 * np.pi * np.arange(n_days) / 7)\n",
    "noise = np.random.normal(0, 8, n_days)\n",
    "values = trend + seasonal_yearly + seasonal_weekly + noise\n",
    "\n",
    "# Add some anomalies\n",
    "anomaly_indices = np.random.choice(n_days, 20, replace=False)\n",
    "values[anomaly_indices] += np.random.choice([-50, 50], 20)\n",
    "\n",
    "ts_df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'value': values,\n",
    "    'volume': np.random.randint(1000, 10000, n_days)\n",
    "})\n",
    "ts_df.set_index('date', inplace=True)\n",
    "\n",
    "# Time series visualization exercises\n",
    "\n",
    "# 1. Basic time series plot with moving averages\n",
    "ts_df['ma_30'] = # Your code here - 30-day moving average\n",
    "ts_df['ma_90'] = # Your code here - 90-day moving average\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "# Your code here - plot original series and moving averages\n",
    "# Add shaded confidence intervals\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Seasonal decomposition visualization\n",
    "def simple_decomposition(ts, period=365):\n",
    "    # Your code here - implement simple seasonal decomposition\n",
    "    pass\n",
    "\n",
    "trend_comp, seasonal_comp, residual_comp = simple_decomposition(ts_df['value'])\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "# Your code here - plot original, trend, seasonal, and residual components\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Multiple time series comparison\n",
    "# Create additional series for comparison\n",
    "ts_df['series_2'] = values * 0.8 + np.random.normal(0, 5, n_days)\n",
    "ts_df['series_3'] = values * 1.2 + np.random.normal(0, 10, n_days)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "# Your code here - plot multiple series with different y-axes if needed\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Heatmap for temporal patterns\n",
    "ts_df['year'] = ts_df.index.year\n",
    "ts_df['month'] = ts_df.index.month\n",
    "ts_df['day_of_week'] = ts_df.index.dayofweek\n",
    "\n",
    "# Monthly patterns heatmap\n",
    "monthly_avg = # Your code here - average values by year and month\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# Your code here - create heatmap showing monthly patterns\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Anomaly detection visualization\n",
    "def detect_anomalies(series, window=30, threshold=2):\n",
    "    # Your code here - detect anomalies using rolling statistics\n",
    "    pass\n",
    "\n",
    "anomalies = detect_anomalies(ts_df['value'])\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "# Your code here - plot time series with anomalies highlighted\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Forecasting visualization\n",
    "# Simple linear trend forecast\n",
    "train_size = int(0.8 * len(ts_df))\n",
    "train_data = ts_df.iloc[:train_size]\n",
    "test_data = ts_df.iloc[train_size:]\n",
    "\n",
    "# Your code here - create simple forecast and plot with confidence intervals\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "# Plot training data, test data, and forecast\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Time series length: {len(ts_df)} days\")\n",
    "print(f\"Date range: {ts_df.index.min()} to {ts_df.index.max()}\")\n",
    "print(f\"Anomalies detected: {len(anomalies)}\")\n",
    "print(f\"Training data: {len(train_data)} days\")\n",
    "print(f\"Test data: {len(test_data)} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Verify time series visualizations\n",
    "print(f\"Time series created: {len(ts_df) > 1000}\")\n",
    "print(f\"Moving averages calculated: {'ma_30' in ts_df.columns and 'ma_90' in ts_df.columns}\")\n",
    "print(f\"Decomposition components exist: {trend_comp is not None}\")\n",
    "print(f\"Multiple series created: {'series_2' in ts_df.columns}\")\n",
    "print(f\"Time components extracted: {all(col in ts_df.columns for col in ['year', 'month', 'day_of_week'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-4",
   "metadata": {},
   "source": [
    "### 4. Statistical Plots with Seaborn (Mid Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hint-4",
   "metadata": {},
   "source": [
    "<details>\n<summary>ðŸ’¡ Click for hint</summary>\n\n**Interview Focus**: Advanced statistical visualizations for data analysis and hypothesis testing.\n\n**Key concepts**: Distribution plots, regression plots, categorical plots, statistical annotations\n\n**Common Questions**: \"Show statistical relationships?\" \"Compare group distributions?\"\n\n</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive dataset for statistical analysis\n",
    "np.random.seed(789)\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate realistic business dataset\n",
    "stats_df = pd.DataFrame({\n",
    "    'customer_id': range(n_samples),\n",
    "    'age': np.random.normal(35, 12, n_samples),\n",
    "    'income': np.random.lognormal(10.5, 0.5, n_samples),\n",
    "    'spending': np.random.gamma(2, 50, n_samples),\n",
    "    'satisfaction': np.random.beta(2, 1, n_samples) * 10,\n",
    "    'segment': np.random.choice(['Premium', 'Standard', 'Basic'], n_samples, p=[0.2, 0.5, 0.3]),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_samples),\n",
    "    'channel': np.random.choice(['Online', 'Store', 'Mobile'], n_samples, p=[0.4, 0.4, 0.2]),\n",
    "    'tenure_months': np.random.randint(1, 60, n_samples)\n",
    "})\n",
    "\n",
    "# Add some relationships\n",
    "stats_df['spending'] = stats_df['spending'] + 0.01 * stats_df['income'] + np.random.normal(0, 20, n_samples)\n",
    "stats_df['satisfaction'] = np.clip(stats_df['satisfaction'] + 0.02 * stats_df['spending'] / 100, 0, 10)\n",
    "\n",
    "# Statistical visualization exercises\n",
    "\n",
    "# 1. Distribution comparison with multiple groups\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "# Your code here - create distribution plots for different segments\n",
    "# Use distplot, histplot, or kdeplot\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Regression plots with confidence intervals\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "# Your code here - regression plots for income vs spending, spending vs satisfaction\n",
    "# Add confidence intervals and correlation coefficients\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Categorical plots for group comparisons\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "# Your code here - box plots, violin plots, strip plots, swarm plots\n",
    "# Compare spending across segments and regions\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Joint plots for bivariate analysis\n",
    "# Your code here - create joint plot with marginal distributions\n",
    "# Show income vs spending relationship\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 5. Facet grids for multi-dimensional analysis\n",
    "# Your code here - create facet grid showing relationships across multiple categories\n",
    "# Use FacetGrid or relplot\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 6. Statistical annotations and tests\n",
    "from scipy import stats\n",
    "\n",
    "def add_statistical_annotations(ax, data, x_col, y_col, group_col):\n",
    "    # Your code here - add p-values, effect sizes to plots\n",
    "    pass\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# Your code here - box plot with statistical annotations\n",
    "add_statistical_annotations(ax, stats_df, 'segment', 'spending', 'segment')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Correlation analysis with advanced heatmap\n",
    "numeric_cols = ['age', 'income', 'spending', 'satisfaction', 'tenure_months']\n",
    "corr_matrix = stats_df[numeric_cols].corr()\n",
    "\n",
    "# Create mask for upper triangle\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# Your code here - advanced correlation heatmap with mask\n",
    "# Add significance indicators\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Ridge plots for distribution comparison\n",
    "def create_ridge_plot(data, x_col, group_col):\n",
    "    # Your code here - create ridge plot (stacked density plots)\n",
    "    pass\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "create_ridge_plot(stats_df, 'spending', 'segment')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Statistical dataset shape: {stats_df.shape}\")\n",
    "print(f\"Segments: {stats_df['segment'].value_counts()}\")\n",
    "print(f\"Correlation matrix shape: {corr_matrix.shape}\")\n",
    "print(f\"Income-Spending correlation: {corr_matrix.loc['income', 'spending']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Verify statistical plots\n",
    "print(f\"Dataset created: {len(stats_df) == n_samples}\")\n",
    "print(f\"Segments distributed: {stats_df['segment'].nunique() == 3}\")\n",
    "print(f\"Numeric columns identified: {len(numeric_cols) == 5}\")\n",
    "print(f\"Correlations calculated: {not corr_matrix.isnull().any().any()}\")\n",
    "print(f\"Strong correlation exists: {(abs(corr_matrix) > 0.5).sum().sum() > 5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-5",
   "metadata": {},
   "source": [
    "### 5. Multi-Panel Figures and Subplots (Mid Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hint-5",
   "metadata": {},
   "source": [
    "<details>\n<summary>ðŸ’¡ Click for hint</summary>\n\n**Interview Focus**: Complex figure layouts for comprehensive data analysis dashboards.\n\n**Key concepts**: plt.subplots(), GridSpec, figure-level vs axes-level functions\n\n**Common Questions**: \"Create a dashboard-style visualization?\" \"Combine multiple plot types?\"\n\n</details>"
   ]
  }
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Create comprehensive business dashboard data\n",
    "np.random.seed(101)\n",
    "\n",
    "# Sales data\n",
    "dates = pd.date_range('2024-01-01', periods=365, freq='D')\n",
    "sales_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'revenue': np.random.normal(10000, 2000, 365) + 1000 * np.sin(2 * np.pi * np.arange(365) / 365),\n",
    "    'orders': np.random.poisson(50, 365),\n",
    "    'customers': np.random.randint(800, 1200, 365),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], 365)\n",
    "})\n",
    "\n",
    "# Product performance data\n",
    "products = ['Product_A', 'Product_B', 'Product_C', 'Product_D', 'Product_E']\n",
    "product_data = pd.DataFrame({\n",
    "    'product': products,\n",
    "    'sales': np.random.randint(1000, 5000, 5),\n",
    "    'profit_margin': np.random.uniform(0.1, 0.4, 5),\n",
    "    'customer_rating': np.random.uniform(3.5, 5.0, 5)\n",
    "})\n",
    "\n",
    "# Multi-panel visualization exercises\n",
    "\n",
    "# 1. Complex dashboard with GridSpec\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "gs = gridspec.GridSpec(4, 4, figure=fig, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Your code here - create dashboard with:\n",
    "# - Main time series plot (top 2 rows, all columns)\n",
    "# - Revenue by region bar chart (bottom left)\n",
    "# - Product performance scatter (bottom center)\n",
    "# - KPI summary (bottom right)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 2. Subplot with shared axes\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12), sharex=True)\n",
    "# Your code here - create stacked time series plots\n",
    "# Revenue, orders, and customers over time with shared x-axis\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Mixed plot types in subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "# Your code here - create 6 different plot types:\n",
    "# Line plot, bar chart, scatter plot, histogram, box plot, heatmap\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Nested subplots with insets\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Your code here - main plot with inset zoom\n",
    "# Create inset axes for detailed view\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Subplot with different scales\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "ax2 = ax1.twinx()  # Create second y-axis\n",
    "# Your code here - plot revenue and orders with different scales\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Faceted analysis\n",
    "def create_faceted_analysis(data, group_col, metric_cols):\n",
    "    # Your code here - create subplot for each group\n",
    "    pass\n",
    "\n",
    "create_faceted_analysis(sales_data, 'region', ['revenue', 'orders'])\n",
    "plt.show()\n",
    "\n",
    "# 7. Custom layout with annotations\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "# Your code here - create custom layout with text annotations\n",
    "# Add titles, KPIs, and summary statistics\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Sales data shape: {sales_data.shape}\")\n",
    "print(f\"Product data shape: {product_data.shape}\")\n",
    "print(f\"Date range: {sales_data['date'].min()} to {sales_data['date'].max()}\")\n",
    "print(f\"Average daily revenue: ${sales_data['revenue'].mean():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Verify multi-panel figures\n",
    "print(f\"Sales data created: {len(sales_data) == 365}\")\n",
    "print(f\"Product data created: {len(product_data) == 5}\")\n",
    "print(f\"Date range correct: {(sales_data['date'].max() - sales_data['date'].min()).days >= 364}\")\n",
    "print(f\"Revenue data realistic: {1000 < sales_data['revenue'].mean() < 20000}\")\n",
    "print(f\"Multiple regions: {sales_data['region'].nunique() == 4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-6",
   "metadata": {},
   "source": [
    "### 6. Advanced Customization and Styling (Mid-Advanced Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hint-6",
   "metadata": {},
   "source": [
    "<details>\n<summary>ðŸ’¡ Click for hint</summary>\n\n**Interview Focus**: Professional-quality visualizations with custom styling and branding.\n\n**Key concepts**: Custom themes, color palettes, fonts, annotations, legends\n\n**Common Questions**: \"Create publication-ready plots?\" \"Apply consistent styling?\"\n\n</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Advanced customization exercises\n",
    "\n",
    "# 1. Custom theme creation\n",
    "def create_custom_theme():\n",
    "    # Your code here - define custom rcParams\n",
    "    custom_params = {\n",
    "        # Define font, colors, line styles, etc.\n",
    "    }\n",
    "    return custom_params\n",
    "\n",
    "# Apply custom theme\n",
    "custom_theme = create_custom_theme()\n",
    "plt.rcParams.update(custom_theme)\n",
    "\n",
    "# 2. Custom color palettes\n",
    "def create_brand_palette():\n",
    "    # Your code here - define brand colors\n",
    "    pass\n",
    "\n",
    "brand_colors = create_brand_palette()\n",
    "\n",
    "# 3. Advanced annotations and callouts\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Your code here - create plot with advanced annotations\n",
    "# Add arrows, text boxes, highlights\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Custom legends and labels\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Your code here - create plot with custom legend\n",
    "# Multiple legend entries, custom markers, positioning\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Publication-ready scientific plot\n",
    "def create_publication_plot(data, title, save_path=None):\n",
    "    # Your code here - create publication-ready plot\n",
    "    # High DPI, proper fonts, clear labels\n",
    "    pass\n",
    "\n",
    "create_publication_plot(sales_data, \"Revenue Analysis 2024\")\n",
    "plt.show()\n",
    "\n",
    "# 6. Interactive-style plot with hover information\n",
    "def create_interactive_style_plot(data):\n",
    "    # Your code here - simulate interactive features\n",
    "    # Tooltips, highlights, clickable elements\n",
    "    pass\n",
    "\n",
    "create_interactive_style_plot(product_data)\n",
    "plt.show()\n",
    "\n",
    "# 7. Custom axis formatting\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# Your code here - custom axis formatting\n",
    "# Currency formatting, date formatting, custom ticks\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Watermarks and branding\n",
    "def add_watermark(ax, text=\"Company Confidential\", alpha=0.3):\n",
    "    # Your code here - add watermark to plot\n",
    "    pass\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# Your code here - create plot with watermark\n",
    "add_watermark(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. Error bars and confidence intervals\n",
    "def plot_with_uncertainty(x, y, yerr, confidence_level=0.95):\n",
    "    # Your code here - plot with error bars and confidence intervals\n",
    "    pass\n",
    "\n",
    "x_data = np.linspace(0, 10, 20)\n",
    "y_data = 2 * x_data + np.random.normal(0, 1, 20)\n",
    "y_err = np.random.uniform(0.5, 2, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plot_with_uncertainty(x_data, y_data, y_err)\n",
    "plt.show()\n",
    "\n",
    "# 10. 3D visualization styling\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Your code here - create styled 3D plot\n",
    "# Custom viewing angle, lighting, colors\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Advanced customization examples completed!\")\n",
    "print(f\"Custom theme applied: {len(custom_theme) > 0}\")\n",
    "print(f\"Brand colors defined: {brand_colors is not None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Verify advanced customization\n",
    "print(f\"Custom theme created: {custom_theme is not None}\")\n",
    "print(f\"Brand palette defined: {brand_colors is not None}\")\n",
    "print(f\"Test data for uncertainty: {len(x_data) == 20}\")\n",
    "print(f\"Matplotlib 3D available: {'mpl_toolkits.mplot3d' in str(type(Axes3D))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-7",
   "metadata": {},
   "source": [
    "### 7. Geospatial and Network Visualizations (Advanced Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hint-7",
   "metadata": {},
   "source": [
    "<details>\n<summary>ðŸ’¡ Click for hint</summary>\n\n**Interview Focus**: Specialized visualizations for geographic and network data analysis.\n\n**Key concepts**: Map projections, network graphs, spatial analysis, geographic plotting\n\n**Common Questions**: \"Visualize geographic data?\" \"Show network relationships?\"\n\n</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "# Geospatial and network visualization exercises\n",
    "\n",
    "# 1. Geographic scatter plot (simulated map)\n",
    "np.random.seed(202)\n",
    "n_cities = 50\n",
    "\n",
    "# Simulate US city coordinates (simplified)\n",
    "geo_data = pd.DataFrame({\n",
    "    'city': [f'City_{i}' for i in range(n_cities)],\n",
    "    'latitude': np.random.uniform(25, 50, n_cities),\n",
    "    'longitude': np.random.uniform(-125, -65, n_cities),\n",
    "    'population': np.random.lognormal(12, 1, n_cities),\n",
    "    'sales': np.random.uniform(100000, 1000000, n_cities),\n",
    "    'region': np.random.choice(['Northeast', 'Southeast', 'Midwest', 'West'], n_cities)\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "# Your code here - create geographic scatter plot\n",
    "# Size by population, color by sales, add region boundaries\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Choropleth-style visualization\n",
    "def create_choropleth_simulation(data):\n",
    "    # Your code here - simulate choropleth map\n",
    "    # Use patches to create regions with different colors\n",
    "    pass\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "create_choropleth_simulation(geo_data)\n",
    "plt.show()\n",
    "\n",
    "# 3. Network graph visualization\n",
    "# Create sample network data\n",
    "G = nx.erdos_renyi_graph(30, 0.15)\n",
    "# Add attributes\n",
    "for node in G.nodes():\n",
    "    G.nodes[node]['value'] = np.random.randint(10, 100)\n",
    "    G.nodes[node]['category'] = np.random.choice(['A', 'B', 'C'])\n",
    "\n",
    "for edge in G.edges():\n",
    "    G.edges[edge]['weight'] = np.random.uniform(0.1, 1.0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "# Your code here - create network visualizations\n",
    "# Left: basic network, Right: styled network with node sizes and edge weights\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Hierarchical network (tree)\n",
    "T = nx.balanced_tree(3, 3)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Your code here - create hierarchical layout\n",
    "# Use different colors for different levels\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Flow diagram\n",
    "def create_flow_diagram(source_data, target_data, values):\n",
    "    # Your code here - create Sankey-style flow diagram\n",
    "    # Use matplotlib patches and paths\n",
    "    pass\n",
    "\n",
    "sources = ['Source_A', 'Source_B', 'Source_C']\n",
    "targets = ['Target_1', 'Target_2', 'Target_3', 'Target_4']\n",
    "flow_values = np.random.randint(10, 100, (3, 4))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "create_flow_diagram(sources, targets, flow_values)\n",
    "plt.show()\n",
    "\n",
    "# 6. Spatial clustering visualization\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Cluster cities by location\n",
    "coords = geo_data[['latitude', 'longitude']].values\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "clusters = kmeans.fit_predict(coords)\n",
    "geo_data['cluster'] = clusters\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Your code here - visualize spatial clusters\n",
    "# Show cluster centers, color by cluster\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Connection matrix heatmap\n",
    "# Create adjacency matrix from network\n",
    "adj_matrix = nx.adjacency_matrix(G).todense()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# Your code here - create adjacency matrix heatmap\n",
    "# Show network connections as heatmap\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Radial/circular plots\n",
    "def create_radial_plot(categories, values):\n",
    "    # Your code here - create radial bar chart or spider plot\n",
    "    pass\n",
    "\n",
    "categories = ['Sales', 'Marketing', 'Support', 'Development', 'HR']\n",
    "values = np.random.randint(20, 100, 5)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))\n",
    "create_radial_plot(categories, values)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Geographic data shape: {geo_data.shape}\")\n",
    "print(f\"Network nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Network edges: {G.number_of_edges()}\")\n",
    "print(f\"Clusters identified: {len(np.unique(clusters))}\")\n",
    "print(f\"Adjacency matrix shape: {adj_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Verify geospatial and network visualizations\n",
    "print(f\"Geographic data created: {len(geo_data) == n_cities}\")\n",
    "print(f\"Coordinates in valid range: {geo_data['latitude'].between(20, 55).all() and geo_data['longitude'].between(-130, -60).all()}\")\n",
    "print(f\"Network created: {G.number_of_nodes() > 0}\")\n",
    "print(f\"Network has edges: {G.number_of_edges() > 0}\")\n",
    "print(f\"Clusters assigned: {'cluster' in geo_data.columns}\")\n",
    "print(f\"Tree structure created: {T.number_of_nodes() > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-8",
   "metadata": {},
   "source": [
    "### 8. Machine Learning Visualization (Advanced Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hint-8",
   "metadata": {},
   "source": [
    "<details>\n<summary>ðŸ’¡ Click for hint</summary>\n\n**Interview Focus**: Visualizations specific to ML model development and evaluation.\n\n**Key concepts**: ROC curves, confusion matrices, learning curves, feature importance, decision boundaries\n\n**Common Questions**: \"Visualize model performance?\" \"Show feature importance?\"\n\n</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Generate ML datasets\n",
    "np.random.seed(303)\n",
    "\n",
    "# Classification dataset\n",
    "X_class, y_class = make_classification(n_samples=1000, n_features=10, n_informative=5, \n",
    "                                      n_redundant=2, n_clusters_per_class=1, random_state=42)\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
    "\n",
    "# Regression dataset\n",
    "X_reg, y_reg = make_regression(n_samples=1000, n_features=8, noise=0.1, random_state=42)\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train models\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_c, y_train_c)\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train_r, y_train_r)\n",
    "\n",
    "# ML visualization exercises\n",
    "\n",
    "# 1. Feature importance visualization\n",
    "feature_names = [f'Feature_{i}' for i in range(X_class.shape[1])]\n",
    "importances = rf_classifier.feature_importances_\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "# Your code here - create feature importance plots\n",
    "# Bar chart and horizontal bar chart\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Confusion matrix heatmap\n",
    "y_pred_c = rf_classifier.predict(X_test_c)\n",
    "cm = confusion_matrix(y_test_c, y_pred_c)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Your code here - create confusion matrices\n",
    "# Raw counts and normalized percentages\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. ROC curve analysis\n",
    "y_pred_proba = rf_classifier.predict_proba(X_test_c)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test_c, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Compare with logistic regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_c, y_train_c)\n",
    "y_pred_proba_lr = lr.predict_proba(X_test_c)[:, 1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test_c, y_pred_proba_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# Your code here - create ROC curve comparison\n",
    "# Plot both models, add diagonal line, show AUC scores\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Learning curves\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    rf_classifier, X_class, y_class, cv=5, n_jobs=-1, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), random_state=42\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# Your code here - create learning curves\n",
    "# Show training and validation scores with confidence intervals\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Residual plots for regression\n",
    "y_pred_r = rf_regressor.predict(X_test_r)\n",
    "residuals = y_test_r - y_pred_r\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "# Your code here - create residual analysis plots\n",
    "# Residuals vs predicted, residuals histogram, Q-Q plot\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Decision boundary visualization (2D)\n",
    "# Create 2D dataset for visualization\n",
    "X_2d, y_2d = make_classification(n_samples=300, n_features=2, n_redundant=0, \n",
    "                                n_informative=2, n_clusters_per_class=1, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_2d_scaled = scaler.fit_transform(X_2d)\n",
    "\n",
    "# Train classifier on 2D data\n",
    "clf_2d = LogisticRegression(random_state=42)\n",
    "clf_2d.fit(X_2d_scaled, y_2d)\n",
    "\n",
    "def plot_decision_boundary(X, y, classifier, title):\n",
    "    # Your code here - create decision boundary plot\n",
    "    # Create mesh grid, predict on grid, plot contours\n",
    "    pass\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plot_decision_boundary(X_2d_scaled, y_2d, clf_2d, \"Logistic Regression Decision Boundary\")\n",
    "plt.show()\n",
    "\n",
    "# 7. Model comparison dashboard\n",
    "def create_model_comparison_dashboard(models, X_test, y_test, model_names):\n",
    "    # Your code here - create comprehensive model comparison\n",
    "    # Multiple metrics, ROC curves, feature importance\n",
    "    pass\n",
    "\n",
    "models = [rf_classifier, lr]\n",
    "model_names = ['Random Forest', 'Logistic Regression']\n",
    "create_model_comparison_dashboard(models, X_test_c, y_test_c, model_names)\n",
    "plt.show()\n",
    "\n",
    "# 8. Hyperparameter tuning visualization\n",
    "def visualize_hyperparameter_tuning():\n",
    "    # Your code here - simulate hyperparameter tuning results\n",
    "    # Create heatmap of parameter combinations and scores\n",
    "    pass\n",
    "\n",
    "visualize_hyperparameter_tuning()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Classification dataset: {X_class.shape}\")\n",
    "print(f\"Regression dataset: {X_reg.shape}\")\n",
    "print(f\"ROC AUC (RF): {roc_auc:.3f}\")\n",
    "print(f\"ROC AUC (LR): {roc_auc_lr:.3f}\")\n",
    "print(f\"Mean residual: {np.mean(residuals):.6f}\")\n",
    "print(f\"Residual std: {np.std(residuals):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Verify ML visualizations\n",
    "print(f\"Classification model trained: {hasattr(rf_classifier, 'feature_importances_')}\")\n",
    "print(f\"Regression model trained: {hasattr(rf_regressor, 'feature_importances_')}\")\n",
    "print(f\"ROC curve calculated: {len(fpr) > 0 and len(tpr) > 0}\")\n",
    "print(f\"Learning curves computed: {train_scores.shape[0] > 0}\")\n",
    "print(f\"Residuals calculated: {len(residuals) == len(y_test_r)}\")\n",
    "print(f\"2D dataset created: {X_2d.shape[1] == 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-9",
   "metadata": {},
   "source": [
    "### 9. Animation and Interactive Elements (Advanced Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hint-9",
   "metadata": {},
   "source": [
    "<details>\n<summary>ðŸ’¡ Click for hint</summary>\n\n**Interview Focus**: Dynamic visualizations for presentations and data storytelling.\n\n**Key concepts**: matplotlib.animation, interactive widgets, dynamic updates\n\n**Common Questions**: \"Create animated visualizations?\" \"Show data evolution over time?\"\n\n</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.widgets import Slider, Button\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Animation and interactive visualization exercises\n",
    "\n",
    "# 1. Animated line plot (time series evolution)\n",
    "np.random.seed(404)\n",
    "t = np.linspace(0, 2*np.pi, 100)\n",
    "x = np.sin(t)\n",
    "y = np.cos(t)\n",
    "\n",
    "def create_animated_line_plot():\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    line, = ax.plot([], [], 'b-', linewidth=2)\n",
    "    ax.set_xlim(0, 2*np.pi)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title('Animated Sine Wave')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    def animate(frame):\n",
    "        # Your code here - update line data for animation\n",
    "        pass\n",
    "    \n",
    "    # Your code here - create FuncAnimation\n",
    "    # anim = FuncAnimation(fig, animate, frames=len(t), interval=50, blit=True)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# Note: Animation may not display in static notebook\n",
    "anim_fig = create_animated_line_plot()\n",
    "\n",
    "# 2. Animated scatter plot (bubble chart evolution)\n",
    "def create_animated_scatter():\n",
    "    # Your code here - create animated scatter plot\n",
    "    # Show data points moving over time\n",
    "    pass\n",
    "\n",
    "create_animated_scatter()\n",
    "\n",
    "# 3. Interactive plot with sliders\n",
    "def create_interactive_plot():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "    \n",
    "    # Initial parameters\n",
    "    freq_init = 1\n",
    "    amp_init = 1\n",
    "    \n",
    "    t = np.linspace(0, 2*np.pi, 1000)\n",
    "    s = amp_init * np.sin(freq_init * t)\n",
    "    line, = ax.plot(t, s, linewidth=2)\n",
    "    \n",
    "    ax.set_xlim(0, 2*np.pi)\n",
    "    ax.set_ylim(-3, 3)\n",
    "    \n",
    "    # Your code here - create sliders for frequency and amplitude\n",
    "    # Add slider widgets and update functions\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "create_interactive_plot()\n",
    "\n",
    "# 4. Animated bar chart race\n",
    "def create_bar_chart_race():\n",
    "    # Create sample data for bar chart race\n",
    "    categories = ['A', 'B', 'C', 'D', 'E']\n",
    "    n_frames = 50\n",
    "    \n",
    "    # Generate data that changes over time\n",
    "    data = np.random.rand(n_frames, len(categories)).cumsum(axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    def animate_bars(frame):\n",
    "        # Your code here - update bar chart for each frame\n",
    "        pass\n",
    "    \n",
    "    # Your code here - create bar chart race animation\n",
    "    plt.show()\n",
    "\n",
    "create_bar_chart_race()\n",
    "\n",
    "print(\"Animation and interactive visualization examples completed!\")\n",
    "print(\"Note: Some animations may not display in static notebook environments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Verify animation setup\n",
    "print(f\"Animation modules imported: {FuncAnimation is not None}\")\n",
    "print(f\"Widget modules imported: {Slider is not None}\")\n",
    "print(f\"Test data created: {len(t) == 100}\")\n",
    "print(f\"Animation figure created: {anim_fig is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-10",
   "metadata": {},
   "source": [
    "### 10. Performance Optimization and Best Practices (Advanced Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hint-10",
   "metadata": {},
   "source": [
    "<details>\n<summary>ðŸ’¡ Click for hint</summary>\n\n**Interview Focus**: Optimizing visualizations for large datasets and production environments.\n\n**Key concepts**: Memory management, rendering optimization, efficient plotting techniques\n\n**Common Questions**: \"Handle large datasets in plots?\" \"Optimize visualization performance?\"\n\n</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Performance optimization exercises\n",
    "\n",
    "# 1. Efficient plotting for large datasets\n",
    "def compare_plotting_methods(n_points=100000):\n",
    "    # Generate large dataset\n",
    "    x_large = np.random.randn(n_points)\n",
    "    y_large = np.random.randn(n_points)\n",
    "    \n",
    "    # Method 1: Standard scatter plot\n",
    "    start_time = time.time()\n",
    "    fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    # Your code here - standard scatter plot\n",
    "    scatter_time = time.time() - start_time\n",
    "    plt.close(fig1)\n",
    "    \n",
    "    # Method 2: Hexbin plot (more efficient for large data)\n",
    "    start_time = time.time()\n",
    "    fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
    "    # Your code here - hexbin plot\n",
    "    hexbin_time = time.time() - start_time\n",
    "    plt.show()\n",
    "    \n",
    "    # Method 3: 2D histogram\n",
    "    start_time = time.time()\n",
    "    fig3, ax3 = plt.subplots(figsize=(8, 6))\n",
    "    # Your code here - 2D histogram\n",
    "    hist2d_time = time.time() - start_time\n",
    "    plt.show()\n",
    "    \n",
    "    return scatter_time, hexbin_time, hist2d_time\n",
    "\n",
    "# Compare methods\n",
    "times = compare_plotting_methods(50000)  # Reduced for notebook performance\n",
    "print(f\"Plotting time comparison (50k points):\")\n",
    "print(f\"Scatter: {times[0]:.3f}s, Hexbin: {times[1]:.3f}s, Hist2D: {times[2]:.3f}s\")\n",
    "\n",
    "# 2. Memory-efficient line plotting\n",
    "def efficient_line_plotting(n_lines=1000, n_points=1000):\n",
    "    # Your code here - use LineCollection for multiple lines\n",
    "    # More efficient than multiple plot() calls\n",
    "    pass\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "efficient_line_plotting()\n",
    "plt.show()\n",
    "\n",
    "# 3. Rasterization for complex plots\n",
    "def demonstrate_rasterization():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Generate complex scatter data\n",
    "    n_points = 10000\n",
    "    x = np.random.randn(n_points)\n",
    "    y = np.random.randn(n_points)\n",
    "    colors = np.random.rand(n_points)\n",
    "    \n",
    "    # Without rasterization\n",
    "    axes[0].scatter(x, y, c=colors, alpha=0.5, s=1)\n",
    "    axes[0].set_title('Vector (Large file size)')\n",
    "    \n",
    "    # With rasterization\n",
    "    axes[1].scatter(x, y, c=colors, alpha=0.5, s=1, rasterized=True)\n",
    "    axes[1].set_title('Rasterized (Smaller file size)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "demonstrate_rasterization()\n",
    "\n",
    "# 4. Best practices checklist\n",
    "def create_best_practices_example():\n",
    "    # Your code here - demonstrate best practices\n",
    "    # Proper figure sizing, DPI settings, format selection\n",
    "    pass\n",
    "\n",
    "create_best_practices_example()\n",
    "\n",
    "# 5. Performance profiling\n",
    "def profile_plotting_performance():\n",
    "    # Your code here - profile different plotting operations\n",
    "    # Identify bottlenecks in visualization code\n",
    "    pass\n",
    "\n",
    "profile_results = profile_plotting_performance()\n",
    "\n",
    "print(\"Performance optimization examples completed!\")\n",
    "print(f\"Profiling results: {profile_results is not None}\")\n",
    "print(\"\\nKey takeaways:\")\n",
    "print(\"- Use hexbin/hist2d for large scatter plots\")\n",
    "print(\"- Rasterize complex plots for smaller file sizes\")\n",
    "print(\"- Sample data intelligently for visualization\")\n",
    "print(\"- Cache reusable plot elements\")\n",
    "print(\"- Monitor memory usage with large datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Verify performance optimization\n",
    "print(f\"Performance comparison completed: {len(times) == 3}\")\n",
    "print(f\"Hexbin faster than scatter: {times[1] < times[0]}\")\n",
    "print(f\"LineCollection imported: {LineCollection is not None}\")\n",
    "print(f\"Performance optimization demonstrated: {True}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3",
   "language": "python",
   "name": "python3.12.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

