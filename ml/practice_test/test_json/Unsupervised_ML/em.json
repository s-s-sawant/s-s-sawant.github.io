[
    {
        "id": "q1",
        "type": "mcq",
        "question": "What is the main purpose of the Expectation Maximization (EM) algorithm?",
        "options": [
            "To perform supervised classification",
            "To find maximum likelihood estimates for models with latent variables",
            "To reduce dimensionality",
            "To cluster data using density-based methods"
        ],
        "correct": [2]
    },
    {
        "id": "q2",
        "type": "msq",
        "question": "Which of the following are steps in the EM algorithm?",
        "options": [
            "Initialization",
            "Expectation step (E-step)",
            "Maximization step (M-step)",
            "Convergence check"
        ],
        "correct": [1, 2, 3, 4]
    },
    {
        "id": "q3",
        "type": "mcq",
        "question": "Which type of models is EM commonly used for?",
        "options": [
            "Linear regression",
            "Gaussian Mixture Models (GMMs)",
            "Decision Trees",
            "K-Means"
        ],
        "correct": [2]
    },
    {
        "id": "q4",
        "type": "msq",
        "question": "Which of the following are advantages of the EM algorithm?",
        "options": [
            "Can handle missing data",
            "Can estimate parameters of mixture models",
            "Provides soft cluster assignments",
            "Always converges to the global optimum"
        ],
        "correct": [1, 2, 3]
    },
    {
        "id": "q5",
        "type": "mcq",
        "question": "What happens in the E-step of the EM algorithm?",
        "options": [
            "Model parameters are updated",
            "Expected values of latent variables are computed",
            "Data is clustered using K-Means",
            "Covariance matrix is calculated"
        ],
        "correct": [2]
    },
    {
        "id": "q6",
        "type": "msq",
        "question": "Which of the following are limitations of the EM algorithm?",
        "options": [
            "Can converge to local optima",
            "Sensitive to initialization",
            "Computationally expensive for large datasets",
            "Requires labeled data"
        ],
        "correct": [1, 2, 3]
    },
    {
        "id": "q7",
        "type": "mcq",
        "question": "Which library provides EM algorithm implementation for GMMs in Python?",
        "options": [
            "scikit-learn",
            "TensorFlow",
            "nltk",
            "matplotlib"
        ],
        "correct": [1]
    },
    {
        "id": "q8",
        "type": "msq",
        "question": "Which of the following are true about Gaussian Mixture Models (GMMs)?",
        "options": [
            "They assume data is generated from a mixture of Gaussian distributions",
            "They provide soft cluster assignments",
            "They use EM for parameter estimation",
            "They require the number of components to be specified"
        ],
        "correct": [1, 2, 3, 4]
    },
    {
        "id": "q9",
        "type": "mcq",
        "question": "What is the main difference between K-Means and EM for GMMs?",
        "options": [
            "K-Means provides soft assignments, EM provides hard assignments",
            "K-Means is supervised, EM is unsupervised",
            "K-Means provides hard assignments, EM provides soft assignments",
            "K-Means does not use distance metrics"
        ],
        "correct": [3]
    },
    {
        "id": "q10",
        "type": "msq",
        "question": "Which of the following are applications of the EM algorithm?",
        "options": [
            "Clustering",
            "Density estimation",
            "Missing data imputation",
            "Dimensionality reduction"
        ],
        "correct": [1, 2, 3]
    },
    {
        "id": "q11",
        "type": "mcq",
        "question": "What is maximized in the M-step of the EM algorithm?",
        "options": [
            "Log-likelihood",
            "Cluster size",
            "Number of clusters",
            "Covariance"
        ],
        "correct": [1]
    },
    {
        "id": "q12",
        "type": "msq",
        "question": "Which of the following are true about the convergence of EM?",
        "options": [
            "It may converge to a local maximum",
            "It is not guaranteed to find the global optimum",
            "It can be monitored by changes in log-likelihood",
            "It always converges in a finite number of steps"
        ],
        "correct": [1, 2, 3]
    },
    {
        "id": "q13",
        "type": "mcq",
        "question": "What is a latent variable in the context of EM?",
        "options": [
            "An observed variable",
            "A hidden or unobserved variable",
            "A variable with missing values",
            "A principal component"
        ],
        "correct": [2]
    },
    {
        "id": "q14",
        "type": "msq",
        "question": "Which of the following are required to initialize the EM algorithm?",
        "options": [
            "Initial parameter values",
            "Number of components",
            "Random seed",
            "Cluster labels"
        ],
        "correct": [1, 2, 3]
    },
    {
        "id": "q15",
        "type": "mcq",
        "question": "Which step in EM assigns probabilities of cluster membership?",
        "options": [
            "Initialization",
            "E-step",
            "M-step",
            "Convergence check"
        ],
        "correct": [2]
    },
    {
        "id": "q16",
        "type": "msq",
        "question": "Which of the following are outputs of the EM algorithm for GMMs?",
        "options": [
            "Cluster membership probabilities",
            "Means and covariances of Gaussians",
            "Log-likelihood values",
            "Principal components"
        ],
        "correct": [1, 2, 3]
    },
    {
        "id": "q17",
        "type": "mcq",
        "question": "What is the effect of poor initialization in EM?",
        "options": [
            "Faster convergence",
            "Convergence to a suboptimal solution",
            "Always finds the global optimum",
            "No effect"
        ],
        "correct": [2]
    },
    {
        "id": "q18",
        "type": "msq",
        "question": "Which of the following are true about the responsibilities in EM?",
        "options": [
            "They represent the probability of a point belonging to each component",
            "They are computed in the E-step",
            "They sum to one for each data point",
            "They are always binary"
        ],
        "correct": [1, 2, 3]
    },
    {
        "id": "q19",
        "type": "mcq",
        "question": "What is the main limitation of EM for GMMs?",
        "options": [
            "Cannot handle missing data",
            "Sensitive to initialization and local optima",
            "Cannot estimate parameters",
            "Cannot perform clustering"
        ],
        "correct": [2]
    },
    {
        "id": "q20",
        "type": "msq",
        "question": "Which of the following are true about EM?",
        "options": [
            "It is iterative",
            "It is unsupervised",
            "It can be used for mixture models",
            "It always finds the global optimum"
        ],
        "correct": [1, 2, 3]
    }
]

